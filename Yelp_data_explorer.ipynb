{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 15:15:31.511517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-19 15:15:31.511547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-19 15:15:31.512256: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-19 15:15:31.516130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "# import cudf as pd\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from geopy import distance\n",
    "import gradio as gr\n",
    "import matplotlib as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Importing, cleaning, and encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json('./Data/yelp_academic_dataset_business.json', lines=True)\n",
    "business_df = business_df[(business_df['state'] == 'TN') & (business_df['is_open'] == 1)]\n",
    "business_df['categories'] = business_df['categories'].fillna('')\n",
    "business_df = business_df[business_df['categories'].str.contains('Restaurants')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_df = pd.read_json('./Data/photos.json', lines=True)\n",
    "photos_df = photos_df.loc[photos_df['business_id'].isin(business_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json('./Data/yelp_academic_dataset_checkin.json', lines=True)\n",
    "checkin_df = checkin_df.loc[checkin_df['business_id'].isin(business_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_chunks = []\n",
    "\n",
    "# for chunk in pd.read_json('./Data/yelp_academic_dataset_review.json', lines=True, chunksize=100000):\n",
    "#     filtered_chunk = chunk.loc[chunk['business_id'].isin(business_df['business_id'])]\n",
    "#     useful_chunks.append(filtered_chunk)\n",
    "\n",
    "# reviews_df = pd.concat(useful_chunks)\n",
    "# reviews_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json('./Data/yelp_academic_dataset_tip.json', lines=True)\n",
    "tip_df = tip_df.loc[tip_df['business_id'].isin(business_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_reviews_df = pd.read_csv('./Data/nashville_business_reviews_summary.csv', sep='|')\n",
    "\n",
    "def integrate_reviews(row, sentiment):\n",
    "    try:\n",
    "        review = summary_reviews_df.loc[(summary_reviews_df['sentiment'] == sentiment) & (summary_reviews_df['business_id'] == row['business_id'])]['summary'].values[0]\n",
    "    except:\n",
    "        review = 'No Reviews'\n",
    "    return review\n",
    "\n",
    "business_df['negative_summary'] = business_df.apply(integrate_reviews,axis=1, args=('negative',))\n",
    "business_df['positive_summary'] = business_df.apply(integrate_reviews,axis=1, args=('positive',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_restaurant_types = business_df['categories'].str.split(',').explode().str.strip().value_counts().index\n",
    "valid_types = all_restaurant_types[:128].tolist()\n",
    "types_to_remove = ['Restaurants','Event Planning & Services','Caterers','Music Venues','Food Delivery Services','Venues & Event Spaces','Hotels & Travel','Convenience Stores','International Grocery','Performing Arts','Florists','Active Life','Food','Nightlife', 'Arcades', 'Flowers & Gifts','Butcher', 'Jazz & Blues','Party & Event Planning','Dance Clubs', \"Arts & Entertainment\", \"Shopping\", \"Ethnic Food\", \"Street Vendors\",\n",
    "    \"Karaoke\", \"Pasta Shops\", \"Meat Shops\", \"Pop-Up Restaurants\", \"Farmers Market\",\"Automotive\"]\n",
    "for type in types_to_remove:\n",
    "    valid_types.remove(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.dropna(subset=['attributes'], inplace=True)\n",
    "#extract: Outdoor Seating, Alcohol, RestaurantsPriceRange2\n",
    "business_df['OutdoorSeating'] = business_df['attributes'].apply(lambda x: x.get('OutdoorSeating', None))\n",
    "business_df['Alcohol'] = business_df['attributes'].apply(lambda x: x.get('Alcohol', None))\n",
    "business_df['RestaurantsPriceRange2'] = business_df['attributes'].apply(lambda x: x.get('RestaurantsPriceRange2', None))\n",
    "\n",
    "#fill outdoor seating with false\n",
    "business_df['OutdoorSeating'].fillna(False, inplace=True)\n",
    "business_df['OutdoorSeating'].replace({'False': False, 'True': True, 'None': False}, inplace=True)\n",
    "#fill alcohol with none\n",
    "business_df['Alcohol'].fillna('none', inplace=True)\n",
    "business_df['Alcohol'].replace({\n",
    "                            \"u'none'\" : 'none',\n",
    "                            \"u'full_bar'\" : 'full_bar',\n",
    "                            \"u'beer_and_wine'\" : 'beer_and_wine',\n",
    "                            \"'none'\" : 'none',\n",
    "                            \"'full_bar'\" : 'full_bar',\n",
    "                            \"'beer_and_wine'\" : 'beer_and_wine',\n",
    "                            }, inplace=True)\n",
    "#fill price range with 2\n",
    "business_df['RestaurantsPriceRange2'].fillna(2, inplace=True)\n",
    "business_df['RestaurantsPriceRange2'] = business_df['RestaurantsPriceRange2'].astype(int)\n",
    "\n",
    "#fill hours with generic hours dict\n",
    "business_df['hours'].fillna(\"{'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'Wednesday': '0:0-0:0', 'Thursday': '0:0-0:0', 'Friday': '0:0-0:0', 'Saturday': '0:0-0:0', 'Sunday': '0:0-0:0'}\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_top_categories(row, valid_types):\n",
    "    row_categories = set(row['categories'])\n",
    "    return [1 if cat in row_categories else 0 for cat in valid_types]\n",
    "\n",
    "\n",
    "business_df['categories'] = business_df['categories'].str.split(',')\n",
    "business_df['categories'] = business_df['categories'].apply(lambda x: [str(cat).strip() for cat in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['Active Life', 'Adult Entertainment', 'Amateur Sports Teams', 'Amusement Parks', 'Aquariums', 'Arcades', 'Argentine', 'Armenian', 'Art Galleries', 'Arts & Crafts', 'Arts & Entertainment', 'Australian', 'Auto Detailing', 'Auto Glass Services', 'Auto Repair', 'Automotive', 'Axe Throwing', 'Bangladeshi', 'Bartenders', 'Beauty & Spas', 'Bed & Breakfast', 'Beer Tours', 'Beverage Store', 'Bistros', 'Boating', 'Books', 'Bowling', 'Brasseries', 'Brazilian', 'British', 'Butcher', 'Cafeteria', 'Candy Stores', 'Cantonese', 'Car Wash', 'Caterers', 'Cheese Shops', 'Chocolatiers & Shops', 'Cideries', 'Cigar Bars', 'Cinema', 'Colombian', 'Comedy Clubs', 'Community Centers', 'Community Service/Non-Profit', 'Contractors', 'Convenience Stores', 'Cooking Classes', 'Cosmetics & Beauty Supply', 'Country Clubs', 'Couriers & Delivery Services', 'Cuban', 'Cultural Center', 'Cupcakes', 'Custom Cakes', 'Dance Clubs', 'Day Spas', 'Department Stores', 'Dim Sum', 'Dinner Theater', 'Distilleries', 'Do-It-Yourself Food', 'Dog Parks', 'Dominican', 'Drugstores', 'Eatertainment', 'Education', 'Egyptian', 'Empanadas', 'Ethical Grocery', 'Ethnic Food', 'Ethnic Grocery', 'Event Planning & Services', 'Falafel', 'Farmers Market', 'Fashion', 'Festivals', 'Filipino', 'Fitness & Instruction', 'Florists', 'Flowers & Gifts', 'Food', 'Food Delivery Services', 'Fruits & Veggies', 'Gas Stations', 'Gay Bars', 'Gelato', 'German', 'Gift Shops', 'Go Karts', 'Golf', 'Grill Services', 'Gymnastics', 'Gyms', 'Hair Salons', 'Health & Medical', 'Heating & Air Conditioning/HVAC', 'Herbs & Spices', 'Himalayan/Nepalese', 'Historical Tours', 'Home & Garden', 'Home Decor', 'Home Organization', 'Home Services', 'Honduran', 'Honey', 'Hospitals', 'Hot Pot', 'Hotels & Travel', 'Imported Food', 'Indoor Playcentre', 'International Grocery', 'Internet Cafes', 'Irish', 'Irish Pub', 'Izakaya', 'Japanese Curry', 'Jazz & Blues', 'Jewelry', 'Karaoke', 'Kebab', 'Kids Activities', 'Kosher', 'Landmarks & Historical Buildings', 'Lebanese', 'Live/Raw Food', 'Local Services', 'Macarons', 'Mags', 'Marinas', 'Mass Media', 'Meat Shops', 'Medical Centers', \"Men's Clothing\", 'Modern European', 'Mongolian', 'Moroccan', 'Municipality', 'Museums', 'Music & Video', 'Music Venues', 'Musicians', 'Nightlife', 'Nutritionists', 'Organic Stores', 'Oriental', 'Outdoor Gear', 'Pakistani', 'Pan Asian', 'Parking', 'Parks', 'Party & Event Planning', 'Pasta Shops', 'Patisserie/Cake Shop', 'Performing Arts', 'Persian/Iranian', 'Personal Chefs', 'Peruvian', 'Pet Adoption', 'Pets', 'Photography Stores & Services', 'Piano Bars', 'Pilates', 'Plumbing', 'Pool Halls', 'Pop-Up Restaurants', 'Pop-up Shops', 'Popcorn Shops', 'Portuguese', 'Pretzels', 'Professional Services', 'Public Markets', 'Public Services & Government', 'Puerto Rican', 'Radio Stations', 'Recording & Rehearsal Studios', 'Recreation Centers', 'Religious Organizations', 'Resorts', 'Restaurants', 'Russian', 'Seafood Markets', 'Septic Services', 'Shaved Ice', 'Shopping', 'Shopping Centers', 'Sicilian', 'Singaporean', 'Skin Care', 'Smokehouse', 'Social Clubs', 'Somali', 'Souvenir Shops', 'Speakeasies', 'Specialty Schools', 'Sporting Goods', 'Sports Clubs', 'Street Vendors', 'Swimming Pools', 'Syrian', 'Tabletop Games', 'Taiwanese', 'Tea Rooms', 'Tennis', 'Teppanyaki', 'Thrift Stores', 'Tiki Bars', 'Tobacco Shops', 'Tours', 'Trainers', 'Travel Services', 'Used', 'Uzbek', 'Venezuelan', 'Venues & Event Spaces', 'Vintage & Consignment', 'Vinyl Records', 'Vitamins & Supplements', 'Water Heater Installation/Repair', 'Water Purification Services', 'Wedding Chapels', 'Wedding Planning', 'Wholesale Stores', 'Wine Tasting Room', 'Wineries', \"Women's Clothing\", 'Yoga'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(classes=valid_types)\n",
    "\n",
    "encoded_array = mlb.fit_transform(business_df['categories'])\n",
    "# Create a DataFrame from the encoded array\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=mlb.classes_, index=business_df.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the new encoded DataFrame\n",
    "business_df = pd.concat([business_df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencode alcohol, outdoor seating, and price using pandas get_dummies\n",
    "business_df = pd.get_dummies(business_df, columns=['Alcohol', 'OutdoorSeating', 'RestaurantsPriceRange2'], dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the review data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(business_df[['stars']])\n",
    "business_df['stars_scaled'] = scaler.transform(business_df[['stars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### NLP Summarization of the Positive and Negative reviews for each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_review(row):\n",
    "#     if row['stars'] < 3:\n",
    "#         return 'negative'\n",
    "#     elif row['stars'] == 3:\n",
    "#         return 'neutral'\n",
    "#     else:\n",
    "#         return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df['sentiment'] = reviews_df.apply(encode_review, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Load pre-trained model and tokenizer\n",
    "# model_name = 'facebook/bart-large-cnn'  # BART model fine-tuned for CNN/DailyMail summarization\n",
    "# tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "# text_model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "# # text_model = DataParallel(text_model)\n",
    "\n",
    "# # Enable GPU usage\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# text_model.to(device)\n",
    "# # Example function to summarize text using the BART model\n",
    "# def summarize_text(text):\n",
    "#     inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "#     inputs = inputs.to(device)\n",
    "#     summary_ids = text_model.generate(inputs['input_ids'], num_beams=4, max_length=90, early_stopping=True)\n",
    "#     summary_text = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "#     print(summary_text)\n",
    "#     return summary_text\n",
    "\n",
    "# # Group and summarize reviews\n",
    "\n",
    "# grouped_reviews = reviews_df.loc[reviews_df['sentiment'] != 'neutral'].groupby(['business_id', 'sentiment'])['text'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# # Apply the summarization model to the aggregated reviews\n",
    "# grouped_reviews['summary'] = grouped_reviews['text'].apply(summarize_text)\n",
    "\n",
    "# grouped_reviews.to_csv('nashville_business_reviews_summary.csv',sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "#         LSTM(128),\n",
    "#         Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # # Continue with model training\n",
    "\n",
    "\n",
    "# test_reviews_df = reviews_df.copy()\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = re.sub(r'\\W', ' ', str(text))\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\s+[a-z]\\s+', ' ', text)\n",
    "#     text = re.sub(r'^[a-z]\\s+', ' ', text)\n",
    "#     text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "#     return text\n",
    "\n",
    "    \n",
    "# test_reviews_df['review_clean'] = test_reviews_df['text'].apply(clean_text)\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def process_text(text):\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "# test_reviews_df['review_final'] = test_reviews_df['review_clean'].apply(process_text)\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=10000)\n",
    "# tokenizer.fit_on_texts(test_reviews_df['review_final'])\n",
    "# sequences = tokenizer.texts_to_sequences(test_reviews_df['review_final'])\n",
    "\n",
    "# max_length = max(len(x) for x in sequences)  # Or choose a fixed length\n",
    "# review_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# # # Building the model\n",
    "# # model = Sequential()\n",
    "# # model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "# # model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "# # model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "\n",
    "# # # Compile the model\n",
    "# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Sorting Valid Categories into more general categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT was kind enough to sort my categories\n",
    "\n",
    "american_cuisine = [\n",
    "    \"American (Traditional)\", \"American (New)\", \"Burgers\", \"Barbeque\",\n",
    "    \"Southern\", \"Steakhouses\", \"Comfort Food\", \"Cajun/Creole\", \"Hot Dogs\", \n",
    "    \"New Mexican Cuisine\"\n",
    "]\n",
    "\n",
    "international_cuisine = [\n",
    "    \"Mexican\", \"Tex-Mex\", \"Italian\", \"Chinese\", \"Japanese\", \"Sushi Bars\",\n",
    "    \"Asian Fusion\", \"Mediterranean\", \"Greek\", \"Thai\", \"Latin American\",\n",
    "    \"Middle Eastern\", \"Indian\", \"Vietnamese\", \"French\", \"Korean\", \"Spanish\",\n",
    "    \"Turkish\", \"Caribbean\", \"Ramen\", \"Salvadoran\", \"Poke\", \"Hawaiian\",\n",
    "    \"Laotian\", \"Halal\", \"Ethiopian\", \"African\"\n",
    "]\n",
    "\n",
    "fast_food_casual = [\n",
    "    \"Fast Food\", \"Sandwiches\", \"Pizza\", \"Chicken Wings\", \"Tacos\", \"Diners\",\n",
    "    \"Food Trucks\", \"Hot Dogs\", \"Fish & Chips\", \"Donuts\", \"Waffles\", \"Acai Bowls\",\n",
    "    \"Wraps\", \"Cheesesteaks\", \"Food Court\"\n",
    "]\n",
    "\n",
    "bars_nightlife = [\n",
    "    \"Bars\", \"Cocktail Bars\", \"Sports Bars\", \"Pubs\", \"Lounges\", \"Dive Bars\",\n",
    "    \"Wine Bars\", \"Beer Bar\", \"Tapas/Small Plates\", \"Gastropubs\", \"Breweries\",\n",
    "    \"Brewpubs\", \"Beer Gardens\", \"Whiskey Bars\", \"Hookah Bars\"\n",
    "]\n",
    "\n",
    "health_specialty_foods = [\n",
    "    \"Salad\", \"Vegetarian\", \"Vegan\", \"Gluten-Free\", \"Juice Bars & Smoothies\",\n",
    "    \"Health Markets\"\n",
    "]\n",
    "\n",
    "beverages = [\n",
    "    \"Coffee & Tea\", \"Specialty Food\", \"Wine & Spirits\", \"Beer\", \"Coffee Roasteries\",\n",
    "    \"Bubble Tea\"\n",
    "]\n",
    "\n",
    "desserts_bakeries = [\n",
    "    \"Desserts\", \"Ice Cream & Frozen Yogurt\", \"Bakeries\", \"Creperies\"\n",
    "]\n",
    "\n",
    "cultural_local_flavors = [\n",
    "    \"Local Flavor\", \"Soul Food\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cats = {\n",
    "    'American':american_cuisine,\n",
    "    'International':international_cuisine,\n",
    "    'Health Food':health_specialty_foods,\n",
    "    'Local and Cultural':cultural_local_flavors,\n",
    "    'Fast Food':fast_food_casual,\n",
    "    'Coffee and Beverages':beverages,\n",
    "    'Dessert':desserts_bakeries,\n",
    "    'Bars and Nightlife':bars_nightlife,\n",
    "}\n",
    "\n",
    "price_dict = {\n",
    "    '$':'RestaurantsPriceRange2_1',\n",
    "    '$$':'RestaurantsPriceRange2_2',\n",
    "    '$$$':'RestaurantsPriceRange2_3',\n",
    "    '$$$$':'RestaurantsPriceRange2_4'\n",
    "}\n",
    "\n",
    "bar_dict = {\n",
    "\"Beer and Wine\":'Alcohol_beer_and_wine',\n",
    "\"Full Bar\":'Alcohol_full_bar',\n",
    "\"None\":'Alcohol_none'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Establishing variable weights for restaurant recommendations through cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = business_df.columns[16:]\n",
    "X = business_df[X_list]\n",
    "y = business_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "for column in X_list:\n",
    "    user_dict[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vector = pd.Series(user_dict).values.reshape(1,-1)\n",
    "user_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Creating the no-image-found Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for the image\n",
    "width, height = 200, 200  # Dimensions of the image\n",
    "background_color = 'grey'  # Background color\n",
    "text = 'No Image Found'  # Text to display\n",
    "font_color = 'white'  # Color of the text\n",
    "\n",
    "# Create a new image with the background color\n",
    "no_photos_img = Image.new('RGB', (width, height), color = background_color)\n",
    "\n",
    "# Get a drawing context\n",
    "draw = ImageDraw.Draw(no_photos_img)\n",
    "\n",
    "# Specify a font (optional: specify a path to a .ttf file if a specific font is desired)\n",
    "# font = ImageFont.truetype('arial.ttf', 36)  # Example for custom font\n",
    "# Or use a default font\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# Calculate text width and height\n",
    "text_width, text_height = 75, 75\n",
    "\n",
    "# Calculate position at center\n",
    "x = (width - text_width) / 2\n",
    "y = (height - text_height) / 2\n",
    "\n",
    "# Draw text on image\n",
    "draw.text((x, y), text, font=font, fill=font_color)\n",
    "\n",
    "# Show the image in a viewer\n",
    "# no_photos_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "#     # Initialize the model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # Adding layers to the model\n",
    "#     model.add(Dense(len(X_list), activation='relu', input_dim=X_train.shape[1]))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='categorical',\n",
    "#                   metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test MSE: {mse}, Test MAE: {mae}\")\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_history(history):\n",
    "#     # Plotting training & validation loss values\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.title('Model Loss')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "#     # Plotting training & validation accuracy values\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(history.history['mean_squared_error'])\n",
    "#     plt.plot(history.history['val_mean_squared_error'])\n",
    "#     plt.title('Model Mean Squared Error')\n",
    "#     plt.ylabel('Mean Squared Error')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# plot_history(history)\n",
    "# # Early stopping callback\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Include in the fit function\n",
    "# history_e_s = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# plot_history(history_e_s)\n",
    "# loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test MSE: {mse}, Test MAE: {mae}\")\n",
    "# user_dict = {}\n",
    "# for item in X_list:\n",
    "#     user_dict[item] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Making a UI\n",
    "\n",
    "* from the AirBNB selection, the function will receive a lat-long. That latlong will calculate the distance to every restaurant \n",
    "\n",
    "The user will select:\n",
    "\n",
    "* distance they're willing to travel (slider)\n",
    "* price preferences\n",
    "* food category or specific food\n",
    "* indoor/outdoor\n",
    "* do they want drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_factor = 2.25\n",
    "rating_factor = 1.25\n",
    "weights_array = np.ones_like(user_vector)\n",
    "weights_array[:,:-10] = weight_factor\n",
    "weights_array[:,-1] = rating_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_distances(row,lat,long):\n",
    "    return round(distance.distance((lat,long),(row['latitude'],row['longitude'])).miles,1)\n",
    "\n",
    "def populate_range_df(airbnb_lat, airbnb_long):\n",
    "    business_df['airbnb_range'] = business_df.apply(restaurant_distances, axis=1, args=(airbnb_lat, airbnb_long))\n",
    "\n",
    "def reset_user():\n",
    "    global user_dict\n",
    "    user_dict = {}\n",
    "    for column in X_list:\n",
    "        user_dict[column] = 0\n",
    "    user_dict['stars_scaled'] = rating_factor\n",
    "    print(pd.Series(user_dict).values.reshape(1,-1))\n",
    "\n",
    "def calculate_best_restaurant(choice, option, price_range, indoor_outdoor, drinks, distance):\n",
    "    user_dict['stars_scaled'] = rating_factor\n",
    "    #first - filter by rules-type things (distance)\n",
    "    search_df = business_df.loc[business_df['airbnb_range'] <= distance].copy()\n",
    "\n",
    "    #second - determine if the user choice was a single cuisine or a category\n",
    "    if choice == 'Category':\n",
    "        for cuisine in list_of_cats[option]:\n",
    "            user_dict[cuisine] = weight_factor\n",
    "    else:\n",
    "        user_dict[option] = weight_factor\n",
    "\n",
    "    #third - build the users other choices\n",
    "    for price in price_dict.keys():\n",
    "        if price in price_range:\n",
    "            user_dict[price_dict[price]] = 1\n",
    "    \n",
    "    if indoor_outdoor == 'Outdoor Seating':\n",
    "        user_dict['OutdoorSeating_True'] = 1\n",
    "\n",
    "    if 'None' in drinks:\n",
    "        user_dict['Alcohol_none'] = 1\n",
    "    elif \"Doesn't Matter\" in drinks:\n",
    "        user_dict['Alcohol_beer_and_wine'] = 1\n",
    "        user_dict['Alcohol_full_bar'] = 1\n",
    "        user_dict['Alcohol_none'] = 1\n",
    "    else:\n",
    "        for bar_type in drinks:\n",
    "            user_dict[bar_dict[bar_type]] = 1\n",
    "        \n",
    "    #fourth - calculate cosine similarities\n",
    "    similarities = cosine_similarity(search_df[X_list].values*weights_array, pd.Series(user_dict).values.reshape(1,-1))\n",
    "    print(pd.Series(user_dict).values.reshape(1,-1))\n",
    "    search_df['Match'] = similarities\n",
    "    search_df.sort_values(by='Match', inplace=True, ascending=False)\n",
    "\n",
    "    business_id1, business_id2, business_id3 = search_df.head(3)['business_id'].values.tolist()\n",
    "    search_df.set_index('business_id', drop=True, inplace=True)\n",
    "    search_df.rename(columns={'name':'english_name'}, inplace=True)\n",
    "    business1 = search_df.loc[business_id1]\n",
    "    business2 = search_df.loc[business_id2]\n",
    "    business3 = search_df.loc[business_id3]\n",
    "\n",
    "    business_1_description = f\"{business1.english_name} is located {business1.airbnb_range} miles from your airbnb.\\n\\nThe positive reviews say: {business1.positive_summary}\\n\\nThe negative reviews say: {business1.negative_summary}\"\n",
    "    try:\n",
    "        b1_img = Image.open(f\"./Data/photos/{photos_df.loc[photos_df['business_id'] == business_id1]['photo_id'].values[0]}.jpg\")\n",
    "    except:\n",
    "        b1_img = no_photos_img\n",
    "\n",
    "    business_2_description = f\"{business2.english_name} is located {business2.airbnb_range} miles from your airbnb.\\n\\nThe positive reviews say: {business2.positive_summary}\\n\\nThe negative reviews say: {business2.negative_summary}\"\n",
    "    try:\n",
    "        b2_img = Image.open(f\"./Data/photos/{photos_df.loc[photos_df['business_id'] == business_id2]['photo_id'].values[0]}.jpg\")\n",
    "    except:\n",
    "        b2_img = no_photos_img\n",
    "\n",
    "    business_3_description = f\"{business3.english_name} is located {business3.airbnb_range} miles from your airbnb.\\n\\nThe positive reviews say: {business3.positive_summary}\\n\\nThe negative reviews say: {business3.negative_summary}\"\n",
    "    try:\n",
    "        b3_img = Image.open(f\"./Data/photos/{photos_df.loc[photos_df['business_id'] == business_id3]['photo_id'].values[0]}.jpg\")\n",
    "    except:\n",
    "        b3_img = no_photos_img\n",
    "    return business_1_description, b1_img, business_2_description, b2_img, business_3_description, b3_img\n",
    "\n",
    "def update_options(choice):\n",
    "    if choice == \"Specific Food\":\n",
    "        return gr.Dropdown(choices=valid_types)\n",
    "    elif choice == \"Category\":\n",
    "        return gr.Dropdown(choices=list(list_of_cats.keys()))\n",
    "    return []  # return an empty list if no choice is made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.25]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# populate_range_df(36.269593,-87.058943)\n",
    "reset_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/utils.py:924: UserWarning: Expected 2 arguments for function <function populate_range_df at 0x7728bf5a2b90>, received 0.\n",
      "  warnings.warn(\n",
      "/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/utils.py:928: UserWarning: Expected at least 2 arguments for function <function populate_range_df at 0x7728bf5a2b90>, received 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://71ce15013f2fda6f72.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://71ce15013f2fda6f72.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/helpers.py:940: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/blocks.py\", line 1786, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/blocks.py\", line 1338, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/gradio/utils.py\", line 759, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_852950/1898970381.py\", line 46, in calculate_best_restaurant\n",
      "    similarities = cosine_similarity(search_df[X_list].values*weights_array, pd.Series(user_dict).values.reshape(1,-1))\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/metrics/pairwise.py\", line 1657, in cosine_similarity\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/metrics/pairwise.py\", line 164, in check_pairwise_arrays\n",
      "    X = check_array(\n",
      "  File \"/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1072, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 108)) while a minimum of 1 is required by check_pairwise_arrays.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.25]]\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.25]]\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.25]]\n"
     ]
    }
   ],
   "source": [
    "theme1 = gr.themes.Soft(\n",
    "    primary_hue=\"sky\",\n",
    "    secondary_hue=\"red\",\n",
    "    radius_size=\"lg\",\n",
    ")\n",
    "\n",
    "theme2 = gr.themes.Glass()\n",
    "\n",
    "with gr.Blocks(title='Restaurant Recommendations') as Restaurants:\n",
    "    with gr.Row(variant='compact'):\n",
    "            import_airbnb_button = gr.Button('Import BnB')\n",
    "    with gr.Row():  \n",
    "        with gr.Row():\n",
    "            choice = gr.Radio([\"Specific Food\", \"Category\"], label=\"What would you like to do?\")\n",
    "            option = gr.Dropdown(['Select Specific Food or Category'],label=\"Choose an option\", value='Select Specific Food or Category', scale=2)\n",
    "        with gr.Row():\n",
    "            price_range = gr.CheckboxGroup(['$','$$','$$$','$$$$'], label=\"Price Range\", info=\"What Price Ranges are you feeling?\")\n",
    "            indoor_outdoor = gr.Radio(['Indoor Seating', 'Outdoor Seating'], label='Indoor or Outdoor seating?',)\n",
    "    with gr.Row():\n",
    "        drinks = gr.CheckboxGroup([\"Doesn't Matter\",\"Beer and Wine\",\"Full Bar\",\"None\"], label=\"Alcohol Available?\", info=\"Select what type of drinks you would like available.\")\n",
    "        distance_slider = gr.Slider(value=5, minimum=0.1, maximum=30, label='Max distance from your AirBNB', interactive=True)\n",
    "    with gr.Row():   \n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "        reset_button = gr.Button('Reset User Preferences')\n",
    "\n",
    "    with gr.Row():\n",
    "        output1 = gr.Textbox(scale=3, visible=True, show_label=False, interactive=False)\n",
    "        photo1 = gr.Image(scale=1, visible=True,show_label=False)\n",
    "    with gr.Row():\n",
    "        output2 = gr.Textbox(scale=3, visible=True, show_label=False, interactive=False)\n",
    "        photo2 = gr.Image(scale=1, visible=True,show_label=False)\n",
    "    with gr.Row():\n",
    "        output3 = gr.Textbox(scale=3, visible=True, show_label=False, interactive=False)\n",
    "        photo3 = gr.Image(scale=1, visible=True,show_label=False)\n",
    "\n",
    "    choice.input(update_options, inputs=choice, outputs=option)\n",
    "    submit_btn.click(fn=calculate_best_restaurant, inputs=[choice, option, price_range, indoor_outdoor, drinks, distance_slider], outputs=[output1, photo1, output2, photo2, output3,photo3])\n",
    "    reset_button.click(fn=reset_user)\n",
    "    import_airbnb_button.click(fn=populate_range_df)\n",
    "\n",
    "interface = gr.TabbedInterface([Restaurants], [\"Tabby McTabface\"], theme=theme1)\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_visibility(radial_input):\n",
    "    if radial_input == 'No':\n",
    "        return gr.Textbox(visible=False), gr.Button(visible=False)\n",
    "    else:\n",
    "        return gr.Textbox(visible=True), gr.Button(visible=True)\n",
    "\n",
    "def update_itinerary(query):\n",
    "    response = \"Whatever the model said\"\n",
    "    return response, gr.Radio(['Yes','No'], value=None,label=\"Was this better?\"), gr.Textbox(value=\"\", visible=False), gr.Button(visible=False)\n",
    "\n",
    "theme = gr.themes.Soft()\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    with gr.Row():\n",
    "        click_me = gr.Radio(['Yes','No'])\n",
    "        results_box = gr.Textbox(interactive=False)\n",
    "    with gr.Row():\n",
    "        text_box = gr.Textbox(visible=False)\n",
    "        submit_button2 = gr.Button(visible=False)\n",
    "\n",
    "\n",
    "    click_me.input(update_visibility,inputs=click_me, outputs=[text_box,submit_button2])\n",
    "    submit_button2.click(update_itinerary, inputs=text_box, outputs=[results_box, click_me, text_box, submit_button2])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
