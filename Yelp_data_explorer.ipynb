{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# import cudf as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json('./Data/yelp_academic_dataset_business.json', lines=True)\n",
    "business_df = business_df[(business_df['state'] == 'TN') & (business_df['is_open'] == 1)]\n",
    "business_df['categories'] = business_df['categories'].fillna('')\n",
    "business_df = business_df[business_df['categories'].str.contains('Restaurants')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json('./Data/yelp_academic_dataset_checkin.json', lines=True)\n",
    "checkin_df = checkin_df.loc[checkin_df['business_id'].isin(business_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_chunks = []\n",
    "\n",
    "for chunk in pd.read_json('./Data/yelp_academic_dataset_review.json', lines=True, chunksize=100000):\n",
    "    filtered_chunk = chunk.loc[chunk['business_id'].isin(business_df['business_id'])]\n",
    "    useful_chunks.append(filtered_chunk)\n",
    "\n",
    "reviews_df = pd.concat(useful_chunks)\n",
    "reviews_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json('./Data/yelp_academic_dataset_tip.json', lines=True)\n",
    "tip_df = tip_df.loc[tip_df['business_id'].isin(business_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_reviews_df = pd.read_csv('./Data/nashville_business_reviews_summary.csv', sep='|')\n",
    "\n",
    "def integrate_reviews(row, sentiment):\n",
    "    try:\n",
    "        review = summary_reviews_df.loc[(summary_reviews_df['sentiment'] == sentiment) & (summary_reviews_df['business_id'] == row['business_id'])]['summary'].values[0]\n",
    "    except:\n",
    "        review = 'No Reviews'\n",
    "    return review\n",
    "\n",
    "business_df['negative_summary'] = business_df.apply(integrate_reviews,axis=1, args=('negative',))\n",
    "business_df['positive_summary'] = business_df.apply(integrate_reviews,axis=1, args=('positive',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_restaurant_types = business_df['categories'].str.split(',').explode().str.strip().value_counts().index\n",
    "valid_types = all_restaurant_types[:128].tolist()\n",
    "types_to_remove = ['Restaurants','Event Planning & Services','Caterers','Music Venues','Food Delivery Services','Venues & Event Spaces','Hotels & Travel','Convenience Stores','International Grocery','Performing Arts','Florists','Active Life','Food','Nightlife', 'Arcades', 'Flowers & Gifts','Butcher', 'Jazz & Blues','Party & Event Planning','Dance Clubs', \"Arts & Entertainment\", \"Shopping\", \"Ethnic Food\", \"Street Vendors\",\n",
    "    \"Karaoke\", \"Pasta Shops\", \"Meat Shops\", \"Pop-Up Restaurants\", \"Farmers Market\",\"Automotive\"]\n",
    "for type in types_to_remove:\n",
    "    valid_types.remove(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.dropna(subset=['attributes'], inplace=True)\n",
    "#extract: Outdoor Seating, Alcohol, RestaurantsPriceRange2\n",
    "business_df['OutdoorSeating'] = business_df['attributes'].apply(lambda x: x.get('OutdoorSeating', None))\n",
    "business_df['Alcohol'] = business_df['attributes'].apply(lambda x: x.get('Alcohol', None))\n",
    "business_df['RestaurantsPriceRange2'] = business_df['attributes'].apply(lambda x: x.get('RestaurantsPriceRange2', None))\n",
    "\n",
    "#fill outdoor seating with false\n",
    "business_df['OutdoorSeating'].fillna(False, inplace=True)\n",
    "business_df['OutdoorSeating'].replace({'False': False, 'True': True, 'None': False}, inplace=True)\n",
    "#fill alcohol with none\n",
    "business_df['Alcohol'].fillna('none', inplace=True)\n",
    "business_df['Alcohol'].replace({\n",
    "                            \"u'none'\" : 'none',\n",
    "                            \"u'full_bar'\" : 'full_bar',\n",
    "                            \"u'beer_and_wine'\" : 'beer_and_wine',\n",
    "                            \"'none'\" : 'none',\n",
    "                            \"'full_bar'\" : 'full_bar',\n",
    "                            \"'beer_and_wine'\" : 'beer_and_wine',\n",
    "                            }, inplace=True)\n",
    "#fill price range with 2\n",
    "business_df['RestaurantsPriceRange2'].fillna(2, inplace=True)\n",
    "business_df['RestaurantsPriceRange2'] = business_df['RestaurantsPriceRange2'].astype(int)\n",
    "\n",
    "#fill hours with generic hours dict\n",
    "business_df['hours'].fillna(\"{'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'Wednesday': '0:0-0:0', 'Thursday': '0:0-0:0', 'Friday': '0:0-0:0', 'Saturday': '0:0-0:0', 'Sunday': '0:0-0:0'}\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_top_categories(row, valid_types):\n",
    "    row_categories = set(row['categories'])\n",
    "    return [1 if cat in row_categories else 0 for cat in valid_types]\n",
    "\n",
    "\n",
    "business_df['categories'] = business_df['categories'].str.split(',')\n",
    "business_df['categories'] = business_df['categories'].apply(lambda x: [str(cat).strip() for cat in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattdipinto/miniconda3/envs/rapids-24.02/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['Active Life', 'Adult Entertainment', 'Amateur Sports Teams', 'Amusement Parks', 'Aquariums', 'Arcades', 'Argentine', 'Armenian', 'Art Galleries', 'Arts & Crafts', 'Arts & Entertainment', 'Australian', 'Auto Detailing', 'Auto Glass Services', 'Auto Repair', 'Automotive', 'Axe Throwing', 'Bangladeshi', 'Bartenders', 'Beauty & Spas', 'Bed & Breakfast', 'Beer Tours', 'Beverage Store', 'Bistros', 'Boating', 'Books', 'Bowling', 'Brasseries', 'Brazilian', 'British', 'Butcher', 'Cafeteria', 'Candy Stores', 'Cantonese', 'Car Wash', 'Caterers', 'Cheese Shops', 'Chocolatiers & Shops', 'Cideries', 'Cigar Bars', 'Cinema', 'Colombian', 'Comedy Clubs', 'Community Centers', 'Community Service/Non-Profit', 'Contractors', 'Convenience Stores', 'Cooking Classes', 'Cosmetics & Beauty Supply', 'Country Clubs', 'Couriers & Delivery Services', 'Cuban', 'Cultural Center', 'Cupcakes', 'Custom Cakes', 'Dance Clubs', 'Day Spas', 'Department Stores', 'Dim Sum', 'Dinner Theater', 'Distilleries', 'Do-It-Yourself Food', 'Dog Parks', 'Dominican', 'Drugstores', 'Eatertainment', 'Education', 'Egyptian', 'Empanadas', 'Ethical Grocery', 'Ethnic Food', 'Ethnic Grocery', 'Event Planning & Services', 'Falafel', 'Farmers Market', 'Fashion', 'Festivals', 'Filipino', 'Fitness & Instruction', 'Florists', 'Flowers & Gifts', 'Food', 'Food Delivery Services', 'Fruits & Veggies', 'Gas Stations', 'Gay Bars', 'Gelato', 'German', 'Gift Shops', 'Go Karts', 'Golf', 'Grill Services', 'Gymnastics', 'Gyms', 'Hair Salons', 'Health & Medical', 'Heating & Air Conditioning/HVAC', 'Herbs & Spices', 'Himalayan/Nepalese', 'Historical Tours', 'Home & Garden', 'Home Decor', 'Home Organization', 'Home Services', 'Honduran', 'Honey', 'Hospitals', 'Hot Pot', 'Hotels & Travel', 'Imported Food', 'Indoor Playcentre', 'International Grocery', 'Internet Cafes', 'Irish', 'Irish Pub', 'Izakaya', 'Japanese Curry', 'Jazz & Blues', 'Jewelry', 'Karaoke', 'Kebab', 'Kids Activities', 'Kosher', 'Landmarks & Historical Buildings', 'Lebanese', 'Live/Raw Food', 'Local Services', 'Macarons', 'Mags', 'Marinas', 'Mass Media', 'Meat Shops', 'Medical Centers', \"Men's Clothing\", 'Modern European', 'Mongolian', 'Moroccan', 'Municipality', 'Museums', 'Music & Video', 'Music Venues', 'Musicians', 'Nightlife', 'Nutritionists', 'Organic Stores', 'Oriental', 'Outdoor Gear', 'Pakistani', 'Pan Asian', 'Parking', 'Parks', 'Party & Event Planning', 'Pasta Shops', 'Patisserie/Cake Shop', 'Performing Arts', 'Persian/Iranian', 'Personal Chefs', 'Peruvian', 'Pet Adoption', 'Pets', 'Photography Stores & Services', 'Piano Bars', 'Pilates', 'Plumbing', 'Pool Halls', 'Pop-Up Restaurants', 'Pop-up Shops', 'Popcorn Shops', 'Portuguese', 'Pretzels', 'Professional Services', 'Public Markets', 'Public Services & Government', 'Puerto Rican', 'Radio Stations', 'Recording & Rehearsal Studios', 'Recreation Centers', 'Religious Organizations', 'Resorts', 'Restaurants', 'Russian', 'Seafood Markets', 'Septic Services', 'Shaved Ice', 'Shopping', 'Shopping Centers', 'Sicilian', 'Singaporean', 'Skin Care', 'Smokehouse', 'Social Clubs', 'Somali', 'Souvenir Shops', 'Speakeasies', 'Specialty Schools', 'Sporting Goods', 'Sports Clubs', 'Street Vendors', 'Swimming Pools', 'Syrian', 'Tabletop Games', 'Taiwanese', 'Tea Rooms', 'Tennis', 'Teppanyaki', 'Thrift Stores', 'Tiki Bars', 'Tobacco Shops', 'Tours', 'Trainers', 'Travel Services', 'Used', 'Uzbek', 'Venezuelan', 'Venues & Event Spaces', 'Vintage & Consignment', 'Vinyl Records', 'Vitamins & Supplements', 'Water Heater Installation/Repair', 'Water Purification Services', 'Wedding Chapels', 'Wedding Planning', 'Wholesale Stores', 'Wine Tasting Room', 'Wineries', \"Women's Clothing\", 'Yoga'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=valid_types)\n",
    "\n",
    "encoded_array = mlb.fit_transform(business_df['categories'])\n",
    "# Create a DataFrame from the encoded array\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=mlb.classes_, index=business_df.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the new encoded DataFrame\n",
    "business_df = pd.concat([business_df, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencode alcohol, outdoor seating, and price using pandas get_dummies\n",
    "business_df = pd.get_dummies(business_df, columns=['Alcohol', 'OutdoorSeating', 'RestaurantsPriceRange2'], dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the review data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(business_df[['stars']])\n",
    "business_df['stars_scaled'] = scaler.transform(business_df[['stars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### NLP Summarization of the Positive and Negative reviews for each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_review(row):\n",
    "#     if row['stars'] < 3:\n",
    "#         return 'negative'\n",
    "#     elif row['stars'] == 3:\n",
    "#         return 'neutral'\n",
    "#     else:\n",
    "#         return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df['sentiment'] = reviews_df.apply(encode_review, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.nn import DataParallel\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# # Load pre-trained model and tokenizer\n",
    "# model_name = 'facebook/bart-large-cnn'  # BART model fine-tuned for CNN/DailyMail summarization\n",
    "# tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "# text_model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "# # text_model = DataParallel(text_model)\n",
    "\n",
    "# # Enable GPU usage\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# text_model.to(device)\n",
    "# # Example function to summarize text using the BART model\n",
    "# def summarize_text(text):\n",
    "#     inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "#     inputs = inputs.to(device)\n",
    "#     summary_ids = text_model.generate(inputs['input_ids'], num_beams=4, max_length=90, early_stopping=True)\n",
    "#     summary_text = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "#     print(summary_text)\n",
    "#     return summary_text\n",
    "\n",
    "# # Group and summarize reviews\n",
    "\n",
    "# grouped_reviews = reviews_df.loc[reviews_df['sentiment'] != 'neutral'].groupby(['business_id', 'sentiment'])['text'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# # Apply the summarization model to the aggregated reviews\n",
    "# grouped_reviews['summary'] = grouped_reviews['text'].apply(summarize_text)\n",
    "\n",
    "# grouped_reviews.to_csv('nashville_business_reviews_summary.csv',sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.multiprocessing as mp\n",
    "\n",
    "# def split_dataframe(df, num_chunks):\n",
    "#     chunk_size = len(df) // num_chunks + 1  # Ensuring all data is included\n",
    "#     return [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "# def process_chunk(data_chunk):\n",
    "#     # Example function that could be run in each subprocess\n",
    "#     print(\"Processing\", data_chunk.shape[0], \"records\")\n",
    "#         # Load tokenizer and model inside the function to ensure it's loaded in the correct process\n",
    "#     model_name = 'facebook/bart-large-cnn'\n",
    "#     tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "#     text_model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     text_model.to(device)\n",
    "\n",
    "#     def summarize_text(text):\n",
    "#         inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "#         inputs = inputs.to(device)\n",
    "#         summary_ids = text_model.generate(inputs['input_ids'], num_beams=4, max_length=90, early_stopping=True)\n",
    "#         summary_text = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "#         return summary_text\n",
    "\n",
    "#     # Summarize each piece of text in the chunk\n",
    "#     data_chunk['summary'] = data_chunk['text'].apply(summarize_text)\n",
    "#     return data_chunk\n",
    "\n",
    "\n",
    "# def main(rank, chunks):\n",
    "#     process_chunk(chunks[rank])\n",
    "\n",
    "\n",
    "# chunks = split_dataframe(reviews_df, torch.cuda.device_count())\n",
    "# manager = mp.Manager()\n",
    "# mp.spawn(main, args=(chunks,), nprocs=len(chunks), join=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "#     model = Sequential([\n",
    "#         Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "#         LSTM(128),\n",
    "#         Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # # Continue with model training\n",
    "\n",
    "\n",
    "# test_reviews_df = reviews_df.copy()\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = re.sub(r'\\W', ' ', str(text))\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\s+[a-z]\\s+', ' ', text)\n",
    "#     text = re.sub(r'^[a-z]\\s+', ' ', text)\n",
    "#     text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "#     return text\n",
    "\n",
    "    \n",
    "# test_reviews_df['review_clean'] = test_reviews_df['text'].apply(clean_text)\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def process_text(text):\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "# test_reviews_df['review_final'] = test_reviews_df['review_clean'].apply(process_text)\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=10000)\n",
    "# tokenizer.fit_on_texts(test_reviews_df['review_final'])\n",
    "# sequences = tokenizer.texts_to_sequences(test_reviews_df['review_final'])\n",
    "\n",
    "# max_length = max(len(x) for x in sequences)  # Or choose a fixed length\n",
    "# review_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# # # Building the model\n",
    "# # model = Sequential()\n",
    "# # model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "# # model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "# # model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "\n",
    "# # # Compile the model\n",
    "# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Sorting Valid Categories into more general categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT was kind enough to sort my categories\n",
    "\n",
    "american_cuisine = [\n",
    "    \"American (Traditional)\", \"American (New)\", \"Burgers\", \"Barbeque\",\n",
    "    \"Southern\", \"Steakhouses\", \"Comfort Food\", \"Cajun/Creole\", \"Hot Dogs\", \n",
    "    \"New Mexican Cuisine\"\n",
    "]\n",
    "\n",
    "international_cuisine = [\n",
    "    \"Mexican\", \"Tex-Mex\", \"Italian\", \"Chinese\", \"Japanese\", \"Sushi Bars\",\n",
    "    \"Asian Fusion\", \"Mediterranean\", \"Greek\", \"Thai\", \"Latin American\",\n",
    "    \"Middle Eastern\", \"Indian\", \"Vietnamese\", \"French\", \"Korean\", \"Spanish\",\n",
    "    \"Turkish\", \"Caribbean\", \"Ramen\", \"Salvadoran\", \"Poke\", \"Hawaiian\",\n",
    "    \"Laotian\", \"Halal\", \"Ethiopian\", \"African\"\n",
    "]\n",
    "\n",
    "fast_food_casual = [\n",
    "    \"Fast Food\", \"Sandwiches\", \"Pizza\", \"Chicken Wings\", \"Tacos\", \"Diners\",\n",
    "    \"Food Trucks\", \"Hot Dogs\", \"Fish & Chips\", \"Donuts\", \"Waffles\", \"Acai Bowls\",\n",
    "    \"Wraps\", \"Cheesesteaks\", \"Food Court\"\n",
    "]\n",
    "\n",
    "bars_nightlife = [\n",
    "    \"Bars\", \"Cocktail Bars\", \"Sports Bars\", \"Pubs\", \"Lounges\", \"Dive Bars\",\n",
    "    \"Wine Bars\", \"Beer Bar\", \"Tapas/Small Plates\", \"Gastropubs\", \"Breweries\",\n",
    "    \"Brewpubs\", \"Beer Gardens\", \"Whiskey Bars\", \"Hookah Bars\"\n",
    "]\n",
    "\n",
    "health_specialty_foods = [\n",
    "    \"Salad\", \"Vegetarian\", \"Vegan\", \"Gluten-Free\", \"Juice Bars & Smoothies\",\n",
    "    \"Health Markets\"\n",
    "]\n",
    "\n",
    "beverages = [\n",
    "    \"Coffee & Tea\", \"Specialty Food\", \"Wine & Spirits\", \"Beer\", \"Coffee Roasteries\",\n",
    "    \"Bubble Tea\"\n",
    "]\n",
    "\n",
    "desserts_bakeries = [\n",
    "    \"Desserts\", \"Ice Cream & Frozen Yogurt\", \"Bakeries\", \"Creperies\"\n",
    "]\n",
    "\n",
    "cultural_local_flavors = [\n",
    "    \"Local Flavor\", \"Soul Food\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cats = {\n",
    "    'American':american_cuisine,\n",
    "    'International':international_cuisine,\n",
    "    'Health Food':health_specialty_foods,\n",
    "    'Local and Cultural':cultural_local_flavors,\n",
    "    'Fast Food':fast_food_casual,\n",
    "    'Coffee and Beverages':beverages,\n",
    "    'Dessert':desserts_bakeries,\n",
    "    'Bars and Nightlife':bars_nightlife,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### A failed experiment in recommending restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_list = business_df.columns[14:-1]\n",
    "# X = business_df[X_list]\n",
    "# y = business_df['name']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "#     # Initialize the model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # Adding layers to the model\n",
    "#     model.add(Dense(len(X_list), activation='relu', input_dim=X_train.shape[1]))  # Adjust input_dim to match the number of one-hot encoded features\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='categorical',\n",
    "#                   metrics=['mean_squared_error', 'mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test MSE: {mse}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_history(history):\n",
    "#     # Plotting training & validation loss values\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.title('Model Loss')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "#     # Plotting training & validation accuracy values\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(history.history['mean_squared_error'])\n",
    "#     plt.plot(history.history['val_mean_squared_error'])\n",
    "#     plt.title('Model Mean Squared Error')\n",
    "#     plt.ylabel('Mean Squared Error')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Early stopping callback\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Include in the fit function\n",
    "# history_e_s = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# plot_history(history_e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test MSE: {mse}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_dict = {}\n",
    "# for item in X_list:\n",
    "#     user_dict[item] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Making a UI\n",
    "\n",
    "* from the AirBNB selection, the function will receive a lat-long. That latlong will calculate the distance to every restaurant \n",
    "\n",
    "The user will select:\n",
    "\n",
    "* distance they're willing to travel (slider)\n",
    "* price preferences\n",
    "* food category or specific food\n",
    "* indoor/outdoor\n",
    "* do they want drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_distances(row,lat,long):\n",
    "    return distance.distance((lat,long),(row['latitude'],row['longitude'])).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_range_df(airbnb_lat, airbnb_long):\n",
    "    business_df['airbnb_range'] = business_df.apply(restaurant_distances, axis=1, args=(airbnb_lat, airbnb_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 10.9 ms, total: 333 ms\n",
      "Wall time: 332 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "populate_range_df(36.269593,-87.058943)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def closest_match(x):\n",
    "    return x + \": The Definitive Edition\"\n",
    "\n",
    "def Dropdown_list(x):\n",
    "    new_options =  [*options, x + \" Remastered\", x + \": The Remake\", x + \": Game of the Year Edition\", x + \" Steelbook Edition\"]\n",
    "    return gr.Dropdown.update(choices=new_options)\n",
    "\n",
    "\n",
    "def Recommend_new(x):\n",
    "  return x + \": Highest Cosine Similarity\"\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "options = ['Placeholder A', 'Placeholder B', 'Placeholder C']\n",
    "with demo:\n",
    "    text_input = gr.Textbox(label=\"Search bar\")\n",
    "    b1 = gr.Button(\"Match Closest Title\")\n",
    "\n",
    "    text_options = gr.Dropdown(options, label=\"Top 5 options\")\n",
    "    b2 = gr.Button(\"Provide Additional options\")\n",
    "    \n",
    "    new_title = gr.Textbox(label=\"Here you go!\")\n",
    "    b3 = gr.Button(\"Recommend a new title\")\n",
    "\n",
    "    b1.click(closest_match, inputs=text_input, outputs=text_options)\n",
    "    b2.click(Dropdown_list, inputs=text_input, outputs=text_options)\n",
    "    b3.click(Recommend_new, inputs=text_options, outputs=new_title)\n",
    "    # text_options.update(interactive=True)\n",
    "\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7896\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7896/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_options(choice, option):\n",
    "    if choice == \"Specific Food\":\n",
    "        return f\"You chose the specific food: {option}\"\n",
    "    elif choice == \"Category\":\n",
    "        return f\"You are viewing the category: {option}\"\n",
    "    \n",
    "def update_options(choice):\n",
    "    if choice == \"Specific Food\":\n",
    "        return gr.Dropdown(choices=valid_types)\n",
    "    elif choice == \"Category\":\n",
    "        return gr.Dropdown(choices=list(list_of_cats.keys()))\n",
    "    return []  # return an empty list if no choice is made\n",
    "\n",
    "def query_user(cuisine, category, price, in_out, drinks, distance):\n",
    "    print(f\"\"\"Price: {price}\n",
    "            In/Out: {in_out}\n",
    "            drinks: {drinks}\n",
    "            distance: {distance}\n",
    "            \"\"\")\n",
    "\n",
    "with gr.Blocks(theme='default') as demo:\n",
    "    with gr.Row():\n",
    "        choice = gr.Radio([\"Specific Food\", \"Category\"], label=\"What would you like to do?\")\n",
    "        option = gr.Dropdown(['Select Specific Food or Category'],label=\"Choose an option\", value='Select Specific Food or Category', scale=2)\n",
    "    with gr.Row():\n",
    "        price_range = gr.CheckboxGroup(['$','$$','$$$','$$$$'], label=\"Price Range\", info=\"What Price Ranges are you feeling?\")\n",
    "        indoor_outdoor = gr.Radio(['Indoor Seating', 'Outdoor Seating'], label='Indoor or Outdoor seating?')\n",
    "    with gr.Row():\n",
    "        drinks = gr.Radio([\"Doesn't Matter\",\"Beer and Wine\",\"Full Bar\",\"None\"], label=\"Alcohol Available?\", info=\"Select what level of alcohol availability, Full Bar includes Beer and Wine\")\n",
    "        distance = gr.Slider(value=1, minimum=0.1, maximum=20, label='Max distance from your AirBNB', interactive=True)\n",
    "        \n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    output = gr.Label()\n",
    "\n",
    "    choice.input(update_options, inputs=choice, outputs=option)\n",
    "    submit_btn.click(fn=show_options, inputs=[choice, option], outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_interface = gr.Interface(fn=create_user_profile, inputs=[gr.CheckboxGroup(list_of_cats, label=\"General Categories\", info=\"What general category of food would you like?\"), #category - Maybe do a select kinda thing\n",
    "                                                                gr.CheckboxGroup(['$','$$','$$$','$$$$'], label=\"Price Range\", info=\"What Price Ranges are you feeling?\"), #price - need to change to checkboxes\n",
    "                                                                  'slider', #\n",
    "                                                                    'slider',\n",
    "                                                                      'slider',\n",
    "                                                                      'slider']\n",
    "                                                                      , outputs=\"number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
